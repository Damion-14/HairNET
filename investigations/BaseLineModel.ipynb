{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model\n",
    "We will use other pretrained models combined together to generate new hair styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Load the original image\n",
    "image = Image.open(\"output.png\").convert(\"RGB\")\n",
    "\n",
    "# Create a mask image (same size as the input image, filled with black)\n",
    "mask_image = Image.new(\"L\", image.size, 0)  # \"L\" mode is grayscale (black/white)\n",
    "\n",
    "# Define a region to inpaint (e.g., a rectangle)\n",
    "draw = ImageDraw.Draw(mask_image)\n",
    "draw.rectangle([50, 50, 500, 500], fill=255)  # White region (inpaint this part)\n",
    "mask_image.save(\"mask.png\")\n",
    "\n",
    "# Load the Stable Diffusion inpainting model\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe.to(device)\n",
    "\n",
    "# Run inpainting\n",
    "image = pipe(\n",
    "    prompt=\"fade the man up, give him a mohawk\",\n",
    "    image=image,\n",
    "    mask_image=mask_image\n",
    ").images[0]\n",
    "\n",
    "# Save the new image\n",
    "image.save(\"new_image.png\")\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I add the image segmentor so now we can input any image and prompt and new hair will generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # For mask dilation\n",
    "\n",
    "# 1. Load Models\n",
    "segmentation_model = pipeline(\"image-segmentation\", model=\"jonathandinu/face-parsing\")\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe.to(device)\n",
    "\n",
    "# 2. Image Input\n",
    "image = Image.open(\"images/headshot1.jpg\").convert(\"RGB\")\n",
    "\n",
    "# 3. Hair Segmentation\n",
    "segmentation_results = segmentation_model(image)\n",
    "hair_mask = None\n",
    "for result in segmentation_results:\n",
    "    if result[\"label\"].lower() == \"hair\":\n",
    "        hair_mask = result[\"mask\"]\n",
    "        break\n",
    "\n",
    "if hair_mask is None:\n",
    "    raise ValueError(\"Hair segmentation not found in the image.\")\n",
    "\n",
    "# Convert hair_mask to a NumPy array if it's a PIL Image\n",
    "if isinstance(hair_mask, Image.Image):\n",
    "    hair_mask = np.array(hair_mask)\n",
    "\n",
    "# Ensure binary format\n",
    "hair_mask = (hair_mask > 0).astype(np.uint8)\n",
    "\n",
    "# 4. Expand Mask by X pixels (dilate)\n",
    "X = 10  # <-- You can change this to any number of pixels to expand\n",
    "kernel = np.ones((2 * X + 1, 2 * X + 1), np.uint8)\n",
    "dilated_mask = cv2.dilate(hair_mask, kernel, iterations=1)\n",
    "\n",
    "# Convert to PIL Image for inpainting\n",
    "mask_image = Image.fromarray((dilated_mask * 255).astype(np.uint8)).resize(image.size)\n",
    "\n",
    "# 5. Stable Diffusion Inpainting\n",
    "prompt = \"A green afro haircut\"\n",
    "result_image = pipe(\n",
    "    prompt=prompt,\n",
    "    image=image,\n",
    "    mask_image=mask_image\n",
    ").images[0]\n",
    "\n",
    "# 6. Display Input, Mask and Output Images using matplotlib\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Input Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(mask_image, cmap=\"gray\")\n",
    "axs[1].set_title(f\"Expanded Hair Mask (+{X}px)\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "axs[2].imshow(result_image)\n",
    "axs[2].set_title(\"Output Image\")\n",
    "axs[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
